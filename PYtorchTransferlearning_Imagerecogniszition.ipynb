{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PYtorchTransferlearning_Imagerecogniszition.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ragalaa/Machine-Learning-Basics/blob/master/PYtorchTransferlearning_Imagerecogniszition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUhT5Zni62aV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch ## for pytorch\n",
        "import torchvision ## for transfer learnhing models and many other vision related classes\n",
        "from torch import nn ## Core Neural Network Model classes in Pytorch\n",
        "from torch import optim ## Contains several Pytorch optimizer classes\n",
        "import torch.nn.functional as F ## Contains several utilily functions provided by Pytorch\n",
        "\n",
        "from torchvision import datasets, transforms, models ## Many Computer Vision related classes\n",
        "                                                     ## for datasets and transformations etc.\n",
        "from torch.utils.data import * ## Contains several utilily functions for dataset manipulation\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDENGQOBCrQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### https://blogs.oracle.com/datascience/transfer-learning-in-pytorch%2c-part-1%3a-how-to-use-dataloaders-and-build-a-fully-connected-class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tyc7kaW7cMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "0a7d4e92-0b9d-4df3-aeb9-f60fa10441f2"
      },
      "source": [
        "train_dataset = datasets.CIFAR10('Cifar10', train=True,\n",
        "                              download=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10('Cifar10', train=False,\n",
        "                             download=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to Cifar10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:02, 69985332.61it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting Cifar10/cifar-10-python.tar.gz to Cifar10\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlhKzwe07t41",
        "colab_type": "text"
      },
      "source": [
        "This gives us two dataset objects that are of torchvision.datasets.cifar.CIFAR10 type. This is a subclass of the PyTorch dataset class, which is the main class to generically represent any dataset. This particular class represents the CIFAR-10 data stored in its internal data structure. Later, these objects shall be passed to a PyTorch Dataloader objects (explained later) for processing the images.\n",
        "\n",
        "We can verify the lengths (number of images) of both datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49ML4Wbg7u2Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f865810e-5f9e-4912-debd-5d7630455e38"
      },
      "source": [
        "len(train_dataset),len(test_dataset)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJKWI2U38tHv",
        "colab_type": "text"
      },
      "source": [
        "Preprocess the Dataset and Prepare It for Training\n",
        "Understand the concept of DataLoader and the PyTorch DataLoader API. Split the images into train, validation, and test sets. Create PyTorch DataLoaders to feed images while training, validation, and prediction. Use PyTorch API to define transforms for preprocessing the dataset for more effective training. Use PyTorch API to convert all images to PyTorch tensors. Normalize the dataset using mean and standard deviation of images.\n",
        "\n",
        "DataLoaders\n",
        "PyTorch DataLoaders are objects that act as Python generators. They supply data in chunks or batches while training and validation. We can instantiate DataLoader objects and pass our datasets to them. DataLoaders store the dataset objects internally.\n",
        "\n",
        "When the application asks for the next batch of data, a DataLoader uses its stored dataset as a Python iterator to get the next element (row or image in our case) of data. Then it aggregates a batch worth of data and returns it to the application.\n",
        "\n",
        "The following is an example of calling the DataLoader constructor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9B57mHa81Kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train = len(train_dataset)\n",
        "indices = list(range(num_train))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=50,sampler=SubsetRandomSampler(indices),\n",
        "                                           num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTvryB5-87L6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f960c454-1d3a-411e-9b84-879166389a35"
      },
      "source": [
        "len(train_loader)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsEik9Y69Hbw",
        "colab_type": "text"
      },
      "source": [
        "Here we are creating a DataLoader object for our training dataset with a batch size of 50. The sampler parameter specifies the strategy with which we want to sample data while constructing batches.\n",
        "\n",
        "We have different samplers available in torch.utils.data.sampler. The explanation is straightforward. You can read about them in the Pytorch Documentation here.\n",
        "\n",
        "The num_workers argument specifies how many processes (or cores) we want to use while loading our data. This provides parallelism while loading large datasets. Default is 0 which means load all data in main process.\n",
        "\n",
        "DataLoader reports its length in number of batches. Since we created this DataLoader with a batch size of 50 and we had 50,000 images in our train dataset, we have the length of dataloader = 1000 batches.\n",
        "\n",
        "Splitting Data\n",
        "Now let's write a function to split our datasets into train, validation, and test sets, and create their corresponding DataLoaders. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLPwV_jE9Ihw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_image_data(train_data,\n",
        "                     test_data=None,\n",
        "                     batch_size=20,\n",
        "                     num_workers=0,\n",
        "                     valid_size=0.2,\n",
        "                     sampler=SubsetRandomSampler):\n",
        "    \n",
        "    num_train = len(train_data)\n",
        "    indices = list(range(num_train))\n",
        "    np.random.shuffle(indices)\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = sampler(train_idx)\n",
        "    valid_sampler = sampler(valid_idx)\n",
        "    if test_data is not None:\n",
        "        test_loader = DataLoader(test_data, batch_size=batch_size,\n",
        "        num_workers=num_workers)\n",
        "    else:\n",
        "        train_idx, test_idx = train_idx[split:],train_idx[:split]\n",
        "        train_sampler = sampler(train_idx)\n",
        "        test_sampler = sampler(test_idx)\n",
        "        \n",
        "        test_loader = torch.utils.data.DataLoader(train_data, \n",
        "                                                  batch_size=batch_size,\n",
        "                                                  sampler=test_sampler,\n",
        "                                                  num_workers=num_workers)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                               batch_size=batch_size,\n",
        "                                               sampler=train_sampler,\n",
        "                                               num_workers=num_workers)\n",
        "    \n",
        "    valid_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                               batch_size=batch_size, \n",
        "                                               sampler=valid_sampler,\n",
        "                                               num_workers=num_workers)\n",
        "    \n",
        "    return train_loader,valid_loader,test_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKFL7boQ9pjN",
        "colab_type": "text"
      },
      "source": [
        "n the above function, test_data can be None in which case it splits train data into train, test, and validation. If test_data is given, it just splits the train set further into train and validation and creates a separate DataLoader from the test set. The function also uses RandomSubsetSampler to shuffle the train and validation set indices. Let's call this function to obtain our DataLoaders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKT6oq0e9qcT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9b6c8984-dbba-4586-bb41-952fd439c3e7"
      },
      "source": [
        "trainloader,validloader,testloader = split_image_data(train_dataset,test_dataset,batch_size=50)\n",
        "\n",
        "len(trainloader),len(testloader),len(validloader)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 200, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XleUF12E-z4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOw1rWIc_Cpb",
        "colab_type": "text"
      },
      "source": [
        "And we have a nice split with 800 batches in our train set and 200 each in our validation and test sets respectively. \n",
        "\n",
        "Preprocessing and Transforming the Dataset\n",
        "Before we move on to defining our network and start training, we need to preprocess our datasets. Specifically, we need to perform the following steps:\n",
        "\n",
        "Resize the images to an appropriate size for our models\n",
        "\n",
        "Perform some basic and most common data augmentation\n",
        "\n",
        "Convert the image data to PyTorch Tensors\n",
        "\n",
        "Normalize the image data\n",
        "\n",
        "Why Do We Want to Resize Images?\n",
        "Most of our transfer learning models require data to be of at least 224x224 size. The reason for this limitation is that these models are designed with a large number of convolution and pooling layers, finally followed by a fully connected (linear) layer at the end to generate the classification output. By the time the input image reaches the final layer, it has been reduced drastically in size due to the way convolutions and pooling are defined. If the input image was already too small (like 32x32 CIFAR-10 images in our case), it would be too small for the network to produce any significant output. Therefore, these models sort of restrict us to input an image >=224x224.\n",
        "\n",
        "Please note that we wouldn't have needed resizing if our images were already > 224x224, such as in the case of ImageNet, or if we were to use our own CNN architecture that did not reduce the image size too much while passing it through layers. Resizing smaller images to larger ones (as in our case) creates artifacts that we don't (ideally) want our model to learn. Since our CIFAR-10 images are really small and the transfer learning models we are using have this requirement, we are obliged to resize.\n",
        "\n",
        "For datasets with larger images, our GPU or CPU memory constraints may become a factor. Therefore, we combine downsizing with increased batch sizes (until we hit the batch size limit) to optimize the model performance and balance the effects of downsizing.\n",
        "\n",
        "Data Augmentation \n",
        "Data augmentation is a common deep learning technique where we modify images on the fly while training the neural network to see additional images flipped or rotated at different axes and angles. This usually results in better training performance since the network sees multiple views of the same image and has a better chance of identifying its class when minimizing the loss function.\n",
        "\n",
        "Note that the augmented images are not added to the dataset. Rather, they are created during batch generation, so the actual images seen during training will increase even though you don't see the number of images in the datasets increasing. The length and other functions that count the number of images will still give the same answer. We use the two common augmentations below:\n",
        "\n",
        "RandomHorizontalFlip that flips some of the images around the vertical axis with a probability p that defaults to 0.5 meaning that 50% of the images shall be flipped.\n",
        "\n",
        "RandomRotation at a specific degree (10 in our case below) that rotates some of them randomly at an angle of 10 degree again with a probability of p which defaults to 0.5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoMLsSSi-4Qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms\n",
        "train_transform = transforms.Compose([transforms.Resize(224),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomRotation(10),\n",
        "                                     ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a6N8X3v_kic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "dataset = datasets.CIFAR10('Cifar10',download=False,transform=transform)\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=50,num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5DEQpGK_Kd1",
        "colab_type": "text"
      },
      "source": [
        "We first create a dataset from full data and then a DataLoader to feed the data in batches of size 50 to our loop. Note that for DataLoader to work, the images have to be converted to a tensor, so that is the only transform we are using.\n",
        "\n",
        "The function below is a straightforward implementation that calculates the mean and std of each batch and adds them to their cumulative sums, dividing in the end by the total number of batches to get the averages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et5uHK-B_MQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_img_stats_avg(loader):\n",
        "    mean = 0.\n",
        "    std = 0.\n",
        "    nb_samples = 0.\n",
        "    for imgs,_ in loader:\n",
        "        batch_samples = imgs.size(0)\n",
        "        imgs = imgs.view(batch_samples, imgs.size(1), -1)\n",
        "        mean += imgs.mean(2).sum(0)\n",
        "        std += imgs.std(2).sum(0)\n",
        "        nb_samples += batch_samples\n",
        "\n",
        "    mean /= nb_samples\n",
        "    std /= nb_samples\n",
        "    return mean,std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFmUI1lS_yGq",
        "colab_type": "text"
      },
      "source": [
        "Data Normalization\n",
        "In data normalization, we statistically normalize the pixel values in our images. This mostly results in better training performance and faster convergence. A common way to perform normalization is to subtract the mean of pixel values of the whole dataset from each pixel, and then divide by the standard deviation of the pixels of the whole dataset.\n",
        "\n",
        "The most common way in transfer learning is to use the mean and std values of the dataset that the original transfer learning model was trained on. However, it may be a good strategy for cases where we don't want to retrain any part of the original model.\n",
        "\n",
        "If our dataset is large and we want to retrain whole or part of the original model, then we would be better off normalizing with the mean and standard deviation of the dataset in question (CIFAR-10, in our case). However, in most transfer learning tutorials, you'll find that the mean and std values for ImageNet are used.\n",
        "\n",
        "Below, I give you two functions to calculate the mean and std of a dataset:\n",
        "\n",
        "1. \"calculate_img_stats_avg\" is based on DataLoader and calculates means and stds of each batch of data as it is retrieved from the dataset object, and finally takes the average of the accumulated means and std values. Although this gives us an approximation of the actual values, it is reasonable to use for large datasets that won't fit into memory at the same time. This code has been adapted from the PyTorch forum.\n",
        "\n",
        "2. \"calculate_img_stats_full\" calculates the actual mean and std of the whole dataset by working on it at once. This gives more accurate values, but will most likely run out of memory for large datasets. For CIFAR-10, this function requires 28GB of RAM. My machine has 32GB but it falls short and I am unable to run this function. This code has been adapted from the book \"Deep Learning with PyTorch\" by Eli Stevens and Luca Antiga, Manning Publications.\n",
        "\n",
        "You can try to run the second function on your specific dataset and if you run into memory issues, then revert to the first one for a good approximation. In case of CIFAR-10, however, many people have calculated the mean and std of the dataset and the values are well known, like ImageNet. We are using those values in the code that follows. I did not try with the approximate values given by the first function but you are welcome to do so ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc-89g0B_NJw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e6308cf9-1a51-4a3f-e14e-1b7e840785a1"
      },
      "source": [
        "calculate_img_stats_avg(loader)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.4914, 0.4822, 0.4465]), tensor([0.2023, 0.1994, 0.2010]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8XQsTCG_3YY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_img_stats_full(dataset):\n",
        "    imgs_ = torch.stack([img for img,_ in dataset],dim=3)\n",
        "    imgs_ = imgs_.view(3,-1)\n",
        "    imgs_mean = imgs_.mean(dim=1)\n",
        "    imgs_std = imgs_.std(dim=1)\n",
        "    return imgs_mean,imgs_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2eT2RNS_6pF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b316c83-5e09-4f12-cfda-7414ce9724bc"
      },
      "source": [
        "calculate_img_stats_full(dataset)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.4915, 0.4823, 0.4468]), tensor([0.2470, 0.2435, 0.2616]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTP4jJ92AAIl",
        "colab_type": "text"
      },
      "source": [
        "The torch.stack function above stacks the data along the given dimension (3, in our case). The view operation views the tensor as a 3 x (product of all other dimensions) which basically flattens while keeping the first dimension as 3. The best way to visualize what is going on in an obscure function like this is to copy isolate the statements and feed them some dummy tensors to see what's going on. I leave it for you as an exercise. Values below have been taken from the same book (referred above from which the code has been taken):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lip3PoOCAEam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar10_mean = [0.4915, 0.4823, 0.4468]\n",
        "cifar10_std  = [0.2470, 0.2435, 0.2616]m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shYEqsmoBQmh",
        "colab_type": "text"
      },
      "source": [
        "Now we can create our datasets again from scratch with all the transformations, augmentations, and normalization applied—splitting them into train and test, and obtaining the final DataLoaders. Note that we also define our batch size = 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8a1jjKrALiy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "153182ab-6d9c-4c42-f90d-e427247857e9"
      },
      "source": [
        "batch_size = 50\n",
        "train_transform = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomRotation(10),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(cifar10_mean, cifar10_std)\n",
        "                                     ])\n",
        "\n",
        "test_transform = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize(cifar10_mean, cifar10_std)\n",
        "                                    ])\n",
        "\n",
        "train_data = datasets.CIFAR10('Cifar10', train=True,\n",
        "                              download=False, transform=train_transform)\n",
        "test_data = datasets.CIFAR10('Cifar10', train=False,\n",
        "                             download=False, transform=test_transform)\n",
        "\n",
        "trainloader,validloader,testloader = split_image_data(train_data,test_data,batch_size=batch_size)\n",
        "\n",
        "len(trainloader),len(testloader),len(validloader)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 200, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJzPU5oNCdZ5",
        "colab_type": "text"
      },
      "source": [
        "toTensor() converts a numpy array to a PyTorch Tensor (all our images are constructed as numpy arrays by the dataset class when read from disk). normalize() is a transform that normalizes according to the passed values of means and STD of each channel as separate lists or tuples."
      ]
    }
  ]
}